{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47f3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, f1_score, recall_score, precision_score, ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pickle\n",
    "from lightgbm import LGBMClassifier\n",
    "import mlflow\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f39e879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 01:54:50 INFO mlflow.tracking.fluent: Experiment with name 'fraud-detection-2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/aravindrajeshmenon/Documents/DataScienceProjects/Projects/fraud_detection/credit_card_fraud/notebook/mlruns/442187196940008915', creation_time=1760316890544, experiment_id='442187196940008915', last_update_time=1760316890544, lifecycle_stage='active', name='fraud-detection-2', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"fraud-detection-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb59c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///Users/aravindrajeshmenon/Documents/DataScienceProjects/Projects/fraud_detection/credit_card_fraud/notebook/mlruns\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de75c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caafb1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee09f7a",
   "metadata": {},
   "source": [
    "We see that since there are no missing values or any categorical values, we can directly move on to modelling the data which simplifies our workload significantly. First, we will run a model with all the variables and then afterwards run a model with a lower number of features that have been removed through some sort of filter (low correlation with target variable, low variance etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc2bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Class'], axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3ae96",
   "metadata": {},
   "source": [
    "Since the data has been setup temporally, we can employ time-series splits to the data, using the first 80% of the data as training data and the remaining 20% of the data as test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83a20ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_ , y_train, y_ = train_test_split(x,y,train_size = 0.8, random_state = 42, stratify = y)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_, y_, train_size = 0.5, random_state = 42, stratify = y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34f4eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=5000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky']\n",
    "for solver in solvers:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"logistic_reg\")\n",
    "        mlflow.log_param(\"solver\", solver)\n",
    "        lr = LogisticRegression(max_iter = 5000, class_weight = 'balanced', solver = solver)\n",
    "        lr.fit(x_train, y_train)\n",
    "        y_pred = lr.predict(x_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa553d65",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "The model demonstrates moderate fraud detection capability but suffers from a significant precision problem. With a recall of 89.3%, the model successfully identifies most fraudulent transactions, catching 67 out of 75 fraud cases. However, the precision of only 7% indicates that the model generates an excessive number of false positives—flagging 880 legitimate transactions as fraudulent.\n",
    "\n",
    "This imbalance results in a low F1-score of 0.13, suggesting the model is currently not production-ready. While the high recall is desirable for minimizing financial losses from missed fraud, the poor precision would lead to poor customer experience, with many legitimate transactions incorrectly declined or flagged for review.\n",
    "\n",
    "To improve model performance, we need to address the class imbalance more effectively through techniques such as SMOTE, adjusting classification thresholds, or exploring ensemble methods. We will first try to employ other baseline models to compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c448036",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'n_estimators' : scope.int(hp.uniform('n_estimators', 100, 250)), \n",
    "    'max_depth' : scope.int(hp.uniform('max_depth', 5, 15)),\n",
    "    'min_samples_split' : hp.choice('min_samples_split',[2,5]),\n",
    "    'min_samples_leaf' : hp.choice('min_samples_leaf', [1,2]),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2'])\n",
    " }\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('model', 'rf')\n",
    "        mlflow.log_params(params)\n",
    "        rf = RandomForestClassifier(n_estimators = params['n_estimators'], \n",
    "        max_depth = params['max_depth'],\n",
    "        class_weight = 'balanced', \n",
    "        min_samples_split = params['min_samples_split'],\n",
    "        min_samples_leaf = params['min_samples_leaf'],\n",
    "        max_features = params['max_features'],\n",
    "        random_state = 42,\n",
    "        )\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "        return {'loss': -f1, 'status': STATUS_OK}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db2b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [25:05<00:00, 75.29s/trial, best loss: -0.8260869565217391]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ca9e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.01,\n",
    "    random_state=42,\n",
    "    subsample=0.9,                \n",
    "    colsample_bytree=0.9,        \n",
    "    gamma=0,\n",
    "    reg_lambda=1.5,                \n",
    "    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]) ,  \n",
    "    eval_metric='aucpr',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7a2d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(data = x_train, label = y_train)\n",
    "valid = xgb.DMatrix(data = x_val, label = y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d628c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", 'xgboost')\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params = params, \n",
    "            dtrain = train, \n",
    "            num_boost_round = 200, \n",
    "            evals=[(train, \"train\"), (valid, \"validation\")],\n",
    "            early_stopping_rounds = 50,\n",
    "            verbose_eval = False\n",
    "        )\n",
    "        y_pred_probs = booster.predict(valid)\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        mlflow.log_metric('f1', f1)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "        plt.savefig(\"conf_matrix.png\")\n",
    "        mlflow.log_artifact(\"conf_matrix.png\")\n",
    "        plt.close()\n",
    "        mlflow.xgboost.log_model(booster, name = \"xgb_mlflow\")\n",
    "        return {'loss': -f1, 'status': STATUS_OK}\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2877b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "client.set_model_version_tag(\n",
    "    name=\"fraud-detection-lgb\",\n",
    "    version=1,\n",
    "    key=\"stage\",\n",
    "    value=\"staging\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268db5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search_runs(\n",
    "    experiment_id = 1, \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3a94d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'n_estimators': scope.int(hp.uniform('n_estimators', 100, 250)),\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 4, 100)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),  # 0.0067 to 1.0\n",
    "    'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'min_child_weight': hp.choice('min_child_weight', [1, 3, 5, 7]),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.5),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, 2),  \n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -5, 2), \n",
    "    'seed' : 42, \n",
    "    'objective' : 'binary:hinge'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ed5fe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:12:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:12:41] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:12:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:03<03:10,  3.89s/trial, best loss: -0.8085106382978723]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:12:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:12:45] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:12:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:06<02:26,  3.04s/trial, best loss: -0.8172043010752689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:12:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:12:47] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:12:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:09<02:16,  2.90s/trial, best loss: -0.8275862068965517]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:12:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:12:50] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:12:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:11<02:09,  2.82s/trial, best loss: -0.8275862068965517]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:12:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:12:53] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:12:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:14<01:59,  2.66s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:12:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:12:55] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:12:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:16<01:52,  2.57s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:12:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:12:58] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:19<01:55,  2.70s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:00] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:21<01:49,  2.60s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:03] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:24<01:45,  2.57s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:05] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:26<01:37,  2.45s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:07] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:28<01:32,  2.37s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:10] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:31<01:33,  2.46s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:12] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:33<01:29,  2.42s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:15] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:36<01:25,  2.38s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:17] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:38<01:21,  2.34s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:19] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:40<01:22,  2.43s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:22] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:43<01:18,  2.37s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:45<01:17,  2.43s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:26] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:47<01:13,  2.37s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:29] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:50<01:12,  2.43s/trial, best loss: -0.8602150537634409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:32] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:53<01:13,  2.52s/trial, best loss: -0.8636363636363636]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:34] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:55<01:10,  2.51s/trial, best loss: -0.8636363636363636]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:37] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:58<01:08,  2.52s/trial, best loss: -0.8636363636363636]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:39] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [01:00<01:05,  2.52s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:42] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:03<01:04,  2.59s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:45] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [01:06<01:02,  2.60s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:47] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [01:08<00:58,  2.55s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:50] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [01:10<00:54,  2.49s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:52] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [01:13<00:52,  2.50s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:54] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:15<00:48,  2.41s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:57] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:13:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:18<00:46,  2.43s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:13:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:13:59] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [01:20<00:44,  2.47s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:02] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [01:23<00:41,  2.41s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:04] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [01:25<00:38,  2.43s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:07] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:28<00:38,  2.57s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:09] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [01:30<00:35,  2.50s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:12] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [01:33<00:33,  2.60s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:15] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [01:36<00:30,  2.55s/trial, best loss: -0.8764044943820225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:17] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:38<00:27,  2.50s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:19] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:40<00:24,  2.48s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:22] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:43<00:22,  2.46s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:24] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [01:45<00:20,  2.53s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:27] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [01:48<00:17,  2.45s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:29] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [01:50<00:15,  2.53s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:53<00:12,  2.54s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:55<00:09,  2.45s/trial, best loss: -0.8791208791208791]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [01:58<00:07,  2.51s/trial, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [02:01<00:05,  2.61s/trial, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [02:03<00:02,  2.56s/trial, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [13:14:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [13:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\n",
      "\u001b[31m2025/10/13 13:14:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:06<00:00,  2.53s/trial, best loss: -0.8888888888888888]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_result = fmin(\n",
    "    fn = objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7161e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/xgboost/callback.py:386: UserWarning: [02:21:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'reg_lambda' : 0.02946709949617557,\n",
    "    'gamma' : 0.4035327095549419,\n",
    "    'seed' : 42,\n",
    "    'max_depth' : 76,\n",
    "    'min_child_weight' : 7,\n",
    "    'learning_rate' : 0.08284903106602773,\n",
    "    'objective' : 'binary:hinge',\n",
    "   'n_estimators' :  141,\n",
    "   'colsample_bytree' : 0.7141674994079779,\n",
    "   'reg_alpha' : 0.048323273989931845,\n",
    "   'subsample' : 0.8550371265419039\n",
    "}\n",
    "\n",
    "\n",
    "booster = xgb.train(\n",
    "    params = params, \n",
    "    dtrain = train, \n",
    "    num_boost_round = 500, \n",
    "    evals = [(train, \"train\"), (valid, \"validation\")],\n",
    "    early_stopping_rounds = 50,\n",
    "    verbose_eval = False\n",
    ")\n",
    "y_pred_probs = booster.predict(valid)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "mlflow.log_metric(\"f1\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b780e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Both Random Forest (F1: 0.83) and XGBoost (F1: 0.82) perform similarly and way better than logistic regression. They're both catching about 72-75% of fraud with high precision (92-98%), but still missing ~25% of fraudulent transactions.\n",
    "\n",
    "**Next steps:**\n",
    "- Try RandomUnderSampler and SMOTE to balance classes better  \n",
    "- Try out neural networks on the normal dataset, as well as the resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b25400f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.5)\n",
    "under = RandomUnderSampler(sampling_strategy=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd0aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.980\n"
     ]
    }
   ],
   "source": [
    "steps =  [('under', under), ('over', over), ('model', lr)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, x_train, y_train, scoring='roc_auc', cv= 3, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56b81ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     28432\n",
      "           1       0.06      0.88      0.11        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.53      0.93      0.55     28481\n",
      "weighted avg       1.00      0.97      0.99     28481\n",
      "\n",
      "[[27711   721]\n",
      " [    6    43]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(x_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad504c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "564009b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 10, 30)),\n",
    "    'num_leaves': scope.int(hp.uniform('num_leaves', 20, 100)),\n",
    "    'min_child_samples': scope.int(hp.uniform('min_child_samples', 10, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'n_estimators': scope.int(hp.uniform('n_estimators', 100, 1000)),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, 0),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -5, 0),\n",
    "    'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
    "}\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('model', 'lightgbm')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        lgb_model = LGBMClassifier(\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "            max_depth = params['max_depth'],\n",
    "            num_leaves = params['num_leaves'],\n",
    "            min_child_samples = params['min_child_samples'],\n",
    "            n_estimators = params['n_estimators'],\n",
    "            reg_alpha = params['reg_alpha'],\n",
    "            reg_lambda = params['reg_lambda'],\n",
    "            subsample = params['subsample'],\n",
    "            colsample_bytree = params['colsample_bytree']\n",
    "    )\n",
    "        lgb_model.fit(x_train, y_train)\n",
    "        y_pred = lgb_model.predict(x_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.lightgbm.log_model(lgb_model, name = 'lgb_model_mlflow')\n",
    "    return {'loss': -f1, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d56fd428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:08:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:06<03:19,  6.87s/trial, best loss: -0.8421052631578947]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:11<02:42,  5.81s/trial, best loss: -0.8631578947368421]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:20<03:06,  6.92s/trial, best loss: -0.8723404255319149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:24<02:32,  5.88s/trial, best loss: -0.8723404255319149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:32<02:44,  6.57s/trial, best loss: -0.8723404255319149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:37<02:28,  6.18s/trial, best loss: -0.8723404255319149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:43<02:19,  6.08s/trial, best loss: -0.8723404255319149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:53<02:41,  7.35s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [01:02<02:42,  7.72s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:09:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [01:08<02:26,  7.32s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:17<02:29,  7.86s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:27<02:30,  8.36s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [01:34<02:14,  7.93s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:42<02:09,  8.09s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:46<01:44,  6.95s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:53<01:35,  6.80s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [01:58<01:23,  6.40s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:10:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [02:07<01:25,  7.09s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [02:15<01:21,  7.39s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [02:21<01:08,  6.84s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [02:28<01:03,  7.04s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [02:34<00:53,  6.71s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [02:43<00:52,  7.48s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [02:52<00:47,  7.87s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [02:58<00:36,  7.31s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:11:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [03:04<00:27,  6.84s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:12:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [03:11<00:20,  6.93s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:12:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [03:22<00:16,  8.05s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:12:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [03:31<00:08,  8.28s/trial, best loss: -0.8817204301075269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/13 11:12:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:38<00:00,  7.28s/trial, best loss: -0.8817204301075269]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5eea1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'm-2a41626d46d54e74aa328b3b1c0aa8be'\n",
    "\n",
    "lgb_loaded_model = mlflow.lightgbm.load_model(f\"models:/{run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bbc5952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.7076870460665258,\n",
       "               max_depth=26, min_child_samples=30, n_estimators=765, n_jobs=-1,\n",
       "               num_leaves=33, random_state=42, reg_alpha=0.12880873757457717,\n",
       "               reg_lambda=0.21294301214260866, subsample=0.9131132760284152,\n",
       "               verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">33</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">26</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">765</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">30</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9131132760284152</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.7076870460665258</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.12880873757457717</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.21294301214260866</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', colsample_bytree=0.7076870460665258,\n",
       "               max_depth=26, min_child_samples=30, n_estimators=765, n_jobs=-1,\n",
       "               num_leaves=33, random_state=42, reg_alpha=0.12880873757457717,\n",
       "               reg_lambda=0.21294301214260866, subsample=0.9131132760284152,\n",
       "               verbose=-1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c4b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.976\n"
     ]
    }
   ],
   "source": [
    "steps =  [('under', under), ('over', over), ('model', lgb_model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, x_train, y_train, scoring='roc_auc', cv= 3, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56887\n",
      "           1       0.05      0.85      0.09        75\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.52      0.92      0.54     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36605bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/lgb_model.pkl', 'wb') as f_out:\n",
    "    pickle.dump(lgb_model, f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
