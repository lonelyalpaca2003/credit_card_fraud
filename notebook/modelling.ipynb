{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47f3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, f1_score, recall_score, precision_score, ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pickle\n",
    "from lightgbm import LGBMClassifier\n",
    "import mlflow\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f39e879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/aravindrajeshmenon/Documents/DataScienceProjects/Projects/fraud_detection/credit_card_fraud/notebook/mlruns/442187196940008915', creation_time=1760316890544, experiment_id='442187196940008915', last_update_time=1760316890544, lifecycle_stage='active', name='fraud-detection-2', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"fraud-detection-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd2697",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de75c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "812672af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee09f7a",
   "metadata": {},
   "source": [
    "Since there are no missing values or any categorical values, we can directly move on to modelling the data which simplifies our workload significantly. First, we will run a model with all the variables and then afterwards run a model with a lower number of features that have been removed through some sort of filter (low correlation with target variable, low variance etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc2bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Class'], axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3ae96",
   "metadata": {},
   "source": [
    "We can now split the data into training and test set. We will then split the test set into the validation and test set to ensure our model gets enough data to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a20ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_ , y_train, y_ = train_test_split(x,y,train_size = 0.8, random_state = 42, stratify = y)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_, y_, train_size = 0.5, random_state = 42, stratify = y_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff9335",
   "metadata": {},
   "source": [
    "### Testing Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34f4eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=5000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10449574726609964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     28432\n",
      "           1       0.06      0.88      0.10        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.53      0.93      0.55     28481\n",
      "weighted avg       1.00      0.97      0.99     28481\n",
      "\n",
      "0.10643564356435643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     28432\n",
      "           1       0.06      0.88      0.11        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.53      0.93      0.55     28481\n",
      "weighted avg       1.00      0.97      0.99     28481\n",
      "\n",
      "0.10696517412935323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     28432\n",
      "           1       0.06      0.88      0.11        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.53      0.93      0.55     28481\n",
      "weighted avg       1.00      0.97      0.99     28481\n",
      "\n",
      "0.1057810578105781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     28432\n",
      "           1       0.06      0.88      0.11        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.53      0.93      0.55     28481\n",
      "weighted avg       1.00      0.97      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky']\n",
    "for solver in solvers:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"logistic_reg\")\n",
    "        mlflow.log_param(\"solver\", solver)\n",
    "        lr = LogisticRegression(max_iter = 5000, class_weight = 'balanced', solver = solver)\n",
    "        lr.fit(x_train, y_train)\n",
    "        y_pred = lr.predict(x_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        print(f1)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        report = classification_report(y_val, y_pred)\n",
    "        print(report)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa553d65",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "The model demonstrates moderate fraud detection capability but suffers from a significant precision problem. With a recall of 89.3%, the model successfully identifies most fraudulent transactions, catching 67 out of 75 fraud cases. However, the precision of only 7% indicates that the model generates an excessive number of false positives with 880 legitimate transactions being flagged as fraudulent.\n",
    "\n",
    "This imbalance results in a low F1-score of 0.13, suggesting the model is not really production-ready. \n",
    "\n",
    "To improve model performance, we need to address the class imbalance more effectively through techniques such as SMOTE or exploring ensemble methods. We will first try to employ other random forest, xgboost and lightgbm models to compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db2b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [25:05<00:00, 75.29s/trial, best loss: -0.8260869565217391]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3ee9c",
   "metadata": {},
   "source": [
    "We see that the random forest method achieves a reasonably good f1 score of 0.82 which is already a massive improvement over the logistic regression model. Now, let us see the f1 scores achieved by the boosted tree methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c9d30",
   "metadata": {},
   "source": [
    "In order to use xgb.train, the dataset has to be converted into a DMatrix. We will first start with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a2d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(data = x_train, label = y_train)\n",
    "valid = xgb.DMatrix(data = x_val, label = y_val)\n",
    "test = xgb.DMatrix(data = x_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d628c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", 'xgboost')\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params = params, \n",
    "            dtrain = train, \n",
    "            num_boost_round = 500, \n",
    "            evals=[(train, \"train\"), (valid, \"validation\")],\n",
    "            early_stopping_rounds = 50,\n",
    "            verbose_eval = False\n",
    "        )\n",
    "        y_pred_probs = booster.predict(valid)\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        mlflow.log_metric('f1', f1)\n",
    "       \n",
    "        return {'loss': -f1, 'status': STATUS_OK}\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a94d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 4, 100)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),  # 0.0067 to 1.0\n",
    "    'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
    "    'min_child_weight': hp.choice('min_child_weight', [1, 3, 5, 7]),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.3),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -2),  \n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -5, -2),\n",
    "    'seed' : 42, \n",
    "    'objective' : 'binary:logistic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed5fe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:02<00:00,  1.21s/trial, best loss: -0.898876404494382] \n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_result = fmin(\n",
    "    fn = objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a9181",
   "metadata": {},
   "source": [
    "We see from the results that the best f1 score achieved across trials is 0.88 which is an even bigger improvement than the random forest model was able to achieve. Before finalising xgboost as the model of choice, let us first also test the lightgbm model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72c1a1",
   "metadata": {},
   "source": [
    "Now, let us try out LightGBM model. We will, as before, define a search space for hyperopt to minimise the loss function, here given by -F1. Then, we will log the parameters as well as the F1 score in each metric to find out the \"best\" parameters. We will then load this model and test on how well it performs on test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df655cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 10, 25)),\n",
    "    'num_leaves': scope.int(hp.uniform('num_leaves', 20, 100)),\n",
    "    'min_child_samples': scope.int(hp.uniform('min_child_samples', 10, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -2.5, 0),\n",
    "    'n_estimators': scope.int(hp.uniform('n_estimators', 100, 1000)),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -2.5),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -5, -3),\n",
    "    'subsample': hp.uniform('subsample', 0.75, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.75, 1.0),\n",
    "}\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('model', 'lightgbm')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        lgb_model = LGBMClassifier(\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "            max_depth = params['max_depth'],\n",
    "            num_leaves = params['num_leaves'],\n",
    "            min_child_samples = params['min_child_samples'],\n",
    "            n_estimators = params['n_estimators'],\n",
    "            reg_alpha = params['reg_alpha'],\n",
    "            reg_lambda = params['reg_lambda'],\n",
    "            subsample = params['subsample'],\n",
    "            colsample_bytree = params['colsample_bytree']\n",
    "    )\n",
    "        lgb_model.fit(x_train, y_train)\n",
    "        y_pred = lgb_model.predict(x_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "    return {'loss': -f1, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007e7531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [09:48<00:00,  3.92s/trial, best loss: -0.8842105263157894]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b780e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Both Random Forest (F1: 0.84) and XGBoost (F1: 0.88) perform similarly and way better than logistic regression. XGBoost in particular iscatching fraud with high precision (92-98%) as well decently high recall as well.\n",
    "\n",
    "**Next steps:**\n",
    "- Try RandomUnderSampler and SMOTE to balance classes better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b25400f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.005)\n",
    "under = RandomUnderSampler(sampling_strategy=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b371ae5",
   "metadata": {},
   "source": [
    "We keep the class imbalance intentionally because fraud is rare in real life. \n",
    "Balancing too much creates unrealistic data that won't work in production.\n",
    "\n",
    "- Undersample to 0.002: This removes most of the majority class to cut down on \n",
    "  computation and noise, but keeps enough samples for the model to learn \n",
    "  normal patterns\n",
    "  \n",
    "- SMOTE (0.005): Adds minimal synthetic fraud cases (bringing fraud to 0.5% of majority)\n",
    "  to slightly improve minority class representation without creating too many fake samples\n",
    "\n",
    "This approach keeps synthetic data minimal and preserves the imbalanced \n",
    "nature of fraud, so the model learns realistic patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd0aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_undersampled, y_train_undersampled= under.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e481d7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    197000\n",
       "1       394\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_undersampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33c10f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resampled,  y_train_resampled = over.fit_resample(x_train_undersampled, y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a596fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    197000\n",
       "1       985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "350648cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_train = xgb.DMatrix(data = x_train_resampled, label = y_train_resampled)\n",
    "valid = xgb.DMatrix(data = x_val, label = y_val)\n",
    "test = xgb.DMatrix(data = x_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed3c55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", 'xgboost_smote')\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params = params, \n",
    "            dtrain = smote_train, \n",
    "            num_boost_round = 500, \n",
    "            evals=[(smote_train, \"train\"), (valid, \"validation\")],\n",
    "            early_stopping_rounds = 50,\n",
    "            verbose_eval = False\n",
    "        )\n",
    "        y_pred_probs = booster.predict(valid)\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        mlflow.log_metric('f1', f1)\n",
    "        return {'loss': -f1, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f623cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 25, 50 )),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, -1),  # 0.0067 to 1.0\n",
    "    'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
    "    'min_child_weight': hp.choice('min_child_weight', [1, 3, 5, 7]),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.2),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -2),  \n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -5, -2), \n",
    "    'seed' : 42, \n",
    "    'objective' : 'binary:logistic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0892bf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:53<00:00,  1.55s/trial, best loss: -0.9010989010989011]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_result = fmin(\n",
    "    fn = objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373de508",
   "metadata": {},
   "source": [
    "We see that hyperopt has been able to achieve a validation f1 score of 0.90 on the resampled data. Now, as the f1 scores of the best XGBoost model trained on the original data as well as the xgboost model trained on the resampled data are quite similar, we need to verify the better model by testing on the test data. In the next section, the best lightgbm model as well as the two XGboost models will be made to predict on the test set to compare their results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa6192d",
   "metadata": {},
   "source": [
    "## Testing the candidate models on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e190a6d",
   "metadata": {},
   "source": [
    "### LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39c03869",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'reg_lambda': 0.006902186066790664,\n",
    "    'max_depth': 32,\n",
    "    'learning_rate': 0.13087526206252295,\n",
    "    'n_estimators': 905,\n",
    "    'min_child_samples': 18,\n",
    "    'num_leaves': 43,\n",
    "    'colsample_bytree': 0.8564403531085696,\n",
    "    'reg_alpha': 0.008070446322648825,\n",
    "    'subsample': 0.8931242253475022\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00f72255",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(**best_params)\n",
    "lgb_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50dcb9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.72      0.84      0.77        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.86      0.92      0.89     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "[[28416    16]\n",
      " [    8    41]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_lgb))\n",
    "print(confusion_matrix(y_test, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8d939",
   "metadata": {},
   "source": [
    "The model achieves 84% recall on fraud detection, successfully catching 41 out of 49 \n",
    "fraudulent transactions. Precision is 72%, meaning 16 legitimate transactions were \n",
    "incorrectly flagged as fraud. Only 8 actual frauds were missed. Overall, the model \n",
    "performs well on the imbalanced dataset while keeping false alarms relatively low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a21d38",
   "metadata": {},
   "source": [
    "### XGBoost model (trained on original data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a466ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-error:0.00067\n",
      "[1]\tvalidation-error:0.00060\n",
      "[2]\tvalidation-error:0.00056\n",
      "[3]\tvalidation-error:0.00056\n",
      "[4]\tvalidation-error:0.00060\n",
      "[5]\tvalidation-error:0.00056\n",
      "[6]\tvalidation-error:0.00053\n",
      "[7]\tvalidation-error:0.00056\n",
      "[8]\tvalidation-error:0.00049\n",
      "[9]\tvalidation-error:0.00046\n",
      "[10]\tvalidation-error:0.00046\n",
      "[11]\tvalidation-error:0.00046\n",
      "[12]\tvalidation-error:0.00046\n",
      "[13]\tvalidation-error:0.00046\n",
      "[14]\tvalidation-error:0.00046\n",
      "[15]\tvalidation-error:0.00049\n",
      "[16]\tvalidation-error:0.00049\n",
      "[17]\tvalidation-error:0.00049\n",
      "[18]\tvalidation-error:0.00049\n",
      "[19]\tvalidation-error:0.00049\n",
      "[20]\tvalidation-error:0.00049\n",
      "[21]\tvalidation-error:0.00049\n",
      "[22]\tvalidation-error:0.00049\n",
      "[23]\tvalidation-error:0.00049\n",
      "[24]\tvalidation-error:0.00049\n",
      "[25]\tvalidation-error:0.00042\n",
      "[26]\tvalidation-error:0.00046\n",
      "[27]\tvalidation-error:0.00042\n",
      "[28]\tvalidation-error:0.00046\n",
      "[29]\tvalidation-error:0.00042\n",
      "[30]\tvalidation-error:0.00042\n",
      "[31]\tvalidation-error:0.00042\n",
      "[32]\tvalidation-error:0.00042\n",
      "[33]\tvalidation-error:0.00042\n",
      "[34]\tvalidation-error:0.00042\n",
      "[35]\tvalidation-error:0.00042\n",
      "[36]\tvalidation-error:0.00042\n",
      "[37]\tvalidation-error:0.00046\n",
      "[38]\tvalidation-error:0.00046\n",
      "[39]\tvalidation-error:0.00046\n",
      "[40]\tvalidation-error:0.00049\n",
      "[41]\tvalidation-error:0.00046\n",
      "[42]\tvalidation-error:0.00046\n",
      "[43]\tvalidation-error:0.00042\n",
      "[44]\tvalidation-error:0.00035\n",
      "[45]\tvalidation-error:0.00042\n",
      "[46]\tvalidation-error:0.00039\n",
      "[47]\tvalidation-error:0.00035\n",
      "[48]\tvalidation-error:0.00039\n",
      "[49]\tvalidation-error:0.00039\n",
      "[50]\tvalidation-error:0.00042\n",
      "[51]\tvalidation-error:0.00042\n",
      "[52]\tvalidation-error:0.00039\n",
      "[53]\tvalidation-error:0.00039\n",
      "[54]\tvalidation-error:0.00039\n",
      "[55]\tvalidation-error:0.00042\n",
      "[56]\tvalidation-error:0.00039\n",
      "[57]\tvalidation-error:0.00039\n",
      "[58]\tvalidation-error:0.00039\n",
      "[59]\tvalidation-error:0.00039\n",
      "[60]\tvalidation-error:0.00039\n",
      "[61]\tvalidation-error:0.00042\n",
      "[62]\tvalidation-error:0.00039\n",
      "[63]\tvalidation-error:0.00042\n",
      "[64]\tvalidation-error:0.00035\n",
      "[65]\tvalidation-error:0.00039\n",
      "[66]\tvalidation-error:0.00035\n",
      "[67]\tvalidation-error:0.00035\n",
      "[68]\tvalidation-error:0.00035\n",
      "[69]\tvalidation-error:0.00039\n",
      "[70]\tvalidation-error:0.00035\n",
      "[71]\tvalidation-error:0.00039\n",
      "[72]\tvalidation-error:0.00035\n",
      "[73]\tvalidation-error:0.00035\n",
      "[74]\tvalidation-error:0.00035\n",
      "[75]\tvalidation-error:0.00035\n",
      "[76]\tvalidation-error:0.00035\n",
      "[77]\tvalidation-error:0.00035\n",
      "[78]\tvalidation-error:0.00039\n",
      "[79]\tvalidation-error:0.00039\n",
      "[80]\tvalidation-error:0.00035\n",
      "[81]\tvalidation-error:0.00035\n",
      "[82]\tvalidation-error:0.00035\n",
      "[83]\tvalidation-error:0.00039\n",
      "[84]\tvalidation-error:0.00032\n",
      "[85]\tvalidation-error:0.00035\n",
      "[86]\tvalidation-error:0.00035\n",
      "[87]\tvalidation-error:0.00035\n",
      "[88]\tvalidation-error:0.00035\n",
      "[89]\tvalidation-error:0.00035\n",
      "[90]\tvalidation-error:0.00039\n",
      "[91]\tvalidation-error:0.00039\n",
      "[92]\tvalidation-error:0.00035\n",
      "[93]\tvalidation-error:0.00035\n",
      "[94]\tvalidation-error:0.00032\n",
      "[95]\tvalidation-error:0.00035\n",
      "[96]\tvalidation-error:0.00035\n",
      "[97]\tvalidation-error:0.00032\n",
      "[98]\tvalidation-error:0.00032\n",
      "[99]\tvalidation-error:0.00032\n",
      "[100]\tvalidation-error:0.00032\n",
      "[101]\tvalidation-error:0.00032\n",
      "[102]\tvalidation-error:0.00035\n",
      "[103]\tvalidation-error:0.00032\n",
      "[104]\tvalidation-error:0.00032\n",
      "[105]\tvalidation-error:0.00032\n",
      "[106]\tvalidation-error:0.00032\n",
      "[107]\tvalidation-error:0.00032\n",
      "[108]\tvalidation-error:0.00032\n",
      "[109]\tvalidation-error:0.00032\n",
      "[110]\tvalidation-error:0.00032\n",
      "[111]\tvalidation-error:0.00032\n",
      "[112]\tvalidation-error:0.00035\n",
      "[113]\tvalidation-error:0.00035\n",
      "[114]\tvalidation-error:0.00032\n",
      "[115]\tvalidation-error:0.00035\n",
      "[116]\tvalidation-error:0.00039\n",
      "[117]\tvalidation-error:0.00032\n",
      "[118]\tvalidation-error:0.00032\n",
      "[119]\tvalidation-error:0.00039\n",
      "[120]\tvalidation-error:0.00035\n",
      "[121]\tvalidation-error:0.00039\n",
      "[122]\tvalidation-error:0.00035\n",
      "[123]\tvalidation-error:0.00035\n",
      "[124]\tvalidation-error:0.00035\n",
      "[125]\tvalidation-error:0.00035\n",
      "[126]\tvalidation-error:0.00035\n",
      "[127]\tvalidation-error:0.00035\n",
      "[128]\tvalidation-error:0.00035\n",
      "[129]\tvalidation-error:0.00035\n",
      "[130]\tvalidation-error:0.00035\n",
      "[131]\tvalidation-error:0.00035\n",
      "[132]\tvalidation-error:0.00035\n",
      "[133]\tvalidation-error:0.00032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/16 00:46:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [00:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\u001b[31m2025/10/16 00:46:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.875\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'reg_lambda': 0.02946709949617557,\n",
    "    'gamma': 0.4035327095549419,\n",
    "    'seed': 42,\n",
    "    'max_depth': 76,\n",
    "    'min_child_weight': 7,\n",
    "    'learning_rate': 0.08284903106602773,\n",
    "    'objective': 'binary:hinge',\n",
    "    'colsample_bytree': 0.7141674994079779,\n",
    "    'reg_alpha': 0.048323273989931845,\n",
    "    'subsample': 0.855037126541903\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=200,\n",
    "        evals=[(valid, \"validation\")],\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    y_pred_proba = booster.predict(test)\n",
    "    y_pred_xgb = (y_pred_proba > 0.5).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_xgb)\n",
    "    \n",
    "    mlflow.xgboost.log_model(booster, \"xgb_model\")\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    \n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dec9a796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.89      0.86      0.88        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.95      0.93      0.94     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "[[28427     5]\n",
      " [    7    42]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144fe10",
   "metadata": {},
   "source": [
    "XGBoost outperforms LightGBM on fraud detection with an F1 score of 0.88 compared to 0.77. \n",
    "It achieves 86% recall vs 84%, catching 42 out of 49 frauds instead of 41. Precision \n",
    "improves significantly to 89% from 72%, reducing false alarms from 16 to just 5. Missed \n",
    "frauds drop from 8 to 7. XGBoost provides better overall balance between catching fraud \n",
    "and minimizing customer disruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../models/xgb_boost.pkl', 'wb') as f_out: \n",
    "    #pickle.dump(booster, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "111ae117",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'reg_lambda': 0.026883404750849747,\n",
    "    'gamma': 0.047305821238349866,\n",
    "    'seed': 42,\n",
    "    'max_depth': 32,\n",
    "    'min_child_weight': 7,\n",
    "    'learning_rate': 0.0913081674061314,\n",
    "    'objective': 'binary:logistic',\n",
    "    'colsample_bytree': 0.9044835863913875,\n",
    "    'reg_alpha': 0.07544378959317678,\n",
    "    'subsample': 0.8414064834751469\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e9ef620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/16 00:53:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/opt/anaconda3/envs/churnenv/lib/python3.13/site-packages/mlflow/xgboost/__init__.py:169: UserWarning: [00:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n",
      "\u001b[31m2025/10/16 00:53:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8541666666666666\n"
     ]
    }
   ],
   "source": [
    "rs_booster = xgb.train(\n",
    "    params = best_params, \n",
    "    dtrain = smote_train, \n",
    "    num_boost_round = 200, \n",
    "    evals = [(train, \"train\"), (valid, \"validation\")],\n",
    "    early_stopping_rounds = 50,\n",
    "    verbose_eval = False\n",
    ")\n",
    "y_pred_probs = rs_booster.predict(test)\n",
    "y_pred_rs = (y_pred_probs > 0.5).astype(int)\n",
    "f1 = f1_score(y_test, y_pred_rs)\n",
    "mlflow.xgboost.log_model(booster, \"xgb_model_rs\")\n",
    "mlflow.log_metric(\"f1\", f1)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfada1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.87      0.84      0.85        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.94      0.92      0.93     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "[[28426     6]\n",
      " [    8    41]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rs))\n",
    "print(confusion_matrix(y_test, y_pred_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6176adc",
   "metadata": {},
   "source": [
    "XGBoost trained on resampled data achieves 84% recall and 87% precision, with an F1 score \n",
    "of 0.85. It catches 41 out of 49 frauds with 6 false alarms and 8 missed frauds. While \n",
    "performance is solid, it's slightly worse than the original XGBoost trained on imbalanced \n",
    "data (F1: 0.88 vs 0.85).\n",
    "\n",
    "Conclusion:\n",
    "The original XGBoost model trained on imbalanced data will be deployed. It achieves the \n",
    "best F1 score (0.88), highest precision (89%), and fewest false alarms (5). Resampling \n",
    "didn't really improve performance, which kinda confirms that maintaining the natural class distribution \n",
    "produces better results for this fraud detection task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
